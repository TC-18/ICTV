\documentclass{llncs}
\usepackage{enumerate}% http://ctan.org/pkg/enumerate
\usepackage{multirow}
\usepackage{amsmath,amssymb}
\usepackage{url}
\usepackage{overpic}
\usepackage{enumerate}
\usepackage{graphicx}        % standard LaTeX graphics tool
\usepackage{tikz}        % standard LaTeX graphics tool
%\usetikzlibrary{arrows}
%\usetikzlibrary{quotes,angles}
\usepackage{subfigure}                                 % authors: subfigures
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}   % authors: last version of algorithm display
\usepackage{todonotes}



\newcommand{\ie}{\emph{i.e.} }
\newcommand{\eg}{\emph{e.g.} }
\newcommand{\wrt}{\emph{w.r.t.} }
\newcommand{\wnlog}{w.l.o.g. }
\newcommand{\Zr}{\ensuremath{\mathbb{Z}[\rho]}}
\newcommand{\C}{\ensuremath{\mathbb{C}}}
\newcommand{\E}{\ensuremath{\mathcal{E}}}

\title{Interactive Curvature Tensor Visualization on Digital
Surfaces\thanks{This work has been mainly funded by XXXXXXX research grants.}}

\author{H\'el\`ene Perrier\inst{1}\and J\'er√©\'emy Levallois\inst{1,2}\and David
Coeurjolly\inst{1}\and Jean-Philippe Farrugia\inst{1}\and Jean-Claude
Iehl\inst{1}\and Jacques-Olivier Lachaud\inst{2} }

%\address[liris]{Universit\'e de Lyon, CNRS, INSA-Lyon, LIRIS, UMR5205, F-69621, France}
%\address[lama]{Universit\'e de Savoie, CNRS, LAMA, UMR 5127, F-73776, France}

 \institute{ Universit\'e de Lyon, CNRS\\
   LIRIS, UMR5205, F-69621, France
%   \email{\{david.coeurjolly,jeremy.levallois\}@liris.cnrs.fr}
   \and
Universit\'e de Savoie, CNRS\\
LAMA, UMR5127, F-73776, France\\
%\email{jacques-olivier.lachaud@univ-savoie.fr}
}

\graphicspath{{./figs/}}
\input{macros}
\begin{document}
\maketitle


\begin{abstract}\sloppy
  Interactive visualization is a very convenient tool to explore
  complex scientific data or to explore different parameter settings
  for a given processing algorithm. In this article, we present a tool
  to efficiently explore the curvature tensor on the boundary of
  potentially large and dynamic digital objects (mean and gaussian curvature,
  principal curvatures, principal directions and normal vector
  field). More precisely, we combine a fully parallel pipeline on GPU
  to extract an adaptive triangulated isosurface of the digital
  object, with a curvature tensor estimation at each surface point
  based on integral invariants. Integral invariants being parametrized
  by a given ball radius, our proposal allows us to explore
  interactively different radii and thus select the appropriate scale
  to which the computation is performed and visualized.


\keywords{Isosurface Visualization, Digital Geometry, Curvature
  Estimation, GPU.}
\end{abstract}

\section{Introduction}
\label{sec:introduction}

Volumetric objects are being more and more popular in many
applications ranging from object modeling and rendering in Computer
Graphics to geometry processing in Medical Imaging or Material
Sciences. When considering large volumetric data, interactive
visualization of such images (or isovalue surfaces) is a complex
problem. Such issues become even more difficult when dynamic
volumetric datasets are considered. Beside such isosurface
visualization, we are also interested in performing geometry
processing on the digital object and to explore different parameter
settings of the geometry processing tool.  In this work, we focus on
interactive visualization of volumetric data isosurfaces combined with
a curvature tensor (mean/Gaussian curvature, principal curvatures
directions\ldots) estimation at each point of the digital
surface. Curvature maps on a given isosurface are key information when
exploring 3D structures in Material Sciences \todo{REF}. Furthermore,
since most curvature estimators require a parameter fixing the scale
to which the computation is performed. For short, such parameter
(integration radius, convolution kernel size, \ldots) specifies noise
level on the object surface. As a consequence, exploring interactively
different values of such parameter is mandatory.
\vspace{0.2cm}

\noindent\textbf{Contributions}\quad In this work, we propose a
framework to perform interactive visualization of complex 3D digital
structures combined with a dynamic curvature tensor estimation. More
precisely, we define a fully data parallel process on GPU hardware \todo{Definir GPU au cas ou ?} to
both efficiently extract adaptive isosurface and compute per vertex
curvature tensor using Integral Invariants estimators. Hence, this
system allows us to visualize curvature tensor in realtime on large
dynamic objects. Our approach combines a GPU implementation of
pointerless octrees to represent the data, an adaptive
viewpoint-dependent mesh extraction, and a GPU implementation of
integral invariant curvature estimations.


\vspace{0.2cm}

\sloppy\noindent\textbf{Related works}\quad Extracting and Visualizing
isosurface on volumetric data has been widely investigated since the
seminal Marching-Cubes approach by Lorensen and
Cline~\cite{lorensen1987marching}. This approach being data parallel,
GPU implementation of this method is very efficient
\cite{tatarchuk2007real}. However, such technique generates a lot of
triangles which is not well suited to large digital data. Hence,
adaptive approaches have been proposed in order to optimize the
triangular mesh resolution to the object geometry or depending on the
viewpoint. In this topic, many solutions have been developed in
Computer
Graphics~\cite{shu1995adaptive,schaefer2004dual,lengyel2010voxel,DBLP:journals/cgf/LewinerMPPL10,DBLP:journals/cvgip/LobelloDD14}.
The method developed by Lengyel \textit{et al.}
\cite{lengyel2010voxel} is the best suited to our needs.  However, it
was developed to visualize in real-time static or near static data and
present a complex CPU implementation.  In this paper we propose a GPU
pipeline inspired from this method.  It leaves the CPU free for other
tasks and avoids synchronisation with the GPU.  Our high framerate
also allows this method to run in real-time on fully dynamic data.
The triangulation is controlled by a GPU LoD criterion that ensures
that triangles project onto more than one pixel, thus removing
geometrical aliasing.

Curvature estimation on discrete or digital surface has also been
widely investigated. In \cite{CVIU2014}, authors propose digital
versions of Integral Invariant estimators
\cite{Pottmann2007,Pottmann2009} in order to estimate the complete
curvature tensor (mean/Gaussian curvatures, principal curvatures,
principal curvature directions, normal vector field) on digital
surfaces. Such approaches are based on an integration principle using
a spherical kernel of a given radius. Additionally, authors have
demonstrated that these estimators have multigrid convergence
properties. In this article, we propose an efficient GPU
implementation of such estimators in order to visualize, in real-time,
such curvature maps and allowing us to interactively explore different
values of the spherical kernel radius.




\section{Curvature Tensor Estimation}
\label{sec:curv-tens-estim}

\sloppy In our context, we consider digital shapes (any subset of $\Z^d$) and
boundaries of digital shapes. We denote by $\DSh$ the Gauss
digitization of $\Shape$ in a $d-$dimensional grid with grid step $h$,
\emph{i.e.}  $\DSh = \Shape \cap (h\Z)^d$. For such digitized set
$\DigShape$, $\partial\Body{\DigShape}{h}$ denotes its
topological boundary, seen as a cellular Cartesian complex (See
Fig. \ref{fig:notations}-b). It is thus composed of $0$-cells and
$1$-cells (resp. \emph{pointels} and \emph{linels}), and, for $d=3$,
with $2$-cells ({\em surfels}), embedded in the digital grid.

\begin{figure}[t]{\small
    \begin{center}
      \subfigure[]{\begin{overpic}[width=5cm]{figs/integral2D_2}
          \put(42,28){$\times$}
          \put(46,31){$\vx$}
          \put(55,45){$B_R(\vx)$}
          \put(1,10){$\dS$}
          \put(20,10){$\Shape$}
      \end{overpic}}
      \subfigure[]{\begin{overpic}[width=5cm]{figs/notation_2}
          \put(44.5,25){$\vp$}
          \put(55,45){$B_R(\vx)$}
          \put(42,28.5){$\times$}
          \put(45,32.5){$\vx$}
          \put(45,16.5){$h$}
          %\put(88,39){$\Proj(p)$}
          \put(3,11){$\partial \Shape$}
          \put(15,7){$\partial \Body{\DigShape}{h}$}
      \end{overpic}}
      \vspace{-0.4cm}
    \end{center}}
    \caption{Integral invariant computation $(a)$ and
      notations $(b)$ in dimension 2 \cite{CVIU2014}.\label{fig:notations}}
\end{figure}

In \cite{DGCI2013}, we have defined the 2D digital curvature estimator
$\CurvH{R}$ and the 3D digital mean curvature estimator $\MeanCurvH{R}$ based on
the digital volumetric integral $V_{R_d}$ (or $A_{R_d}$ in dimension 2) of the
intersection between the shape $\Shape$ and a ball of digital radius $R_d$:
%
\begin{Definition}
  %
  Given the Gauss digitization $\Body{\DSh}{h}$ of a shape $\Shape \subset \R^2$
  (or $\R^3$ for the 3D mean curvature estimator) scaled by the digitization
  step $h$, {\em digital curvature estimators} are defined for any point $\vx
  \in \R^2$ (or $\R^3$) as:
  %
  \begin{align}
    \forall 0 < h < R,\quad
    &\CurvH{R}(\Body{\DSh}{h},\vx,h) \EqDef \frac{3\pi}{2R}
    - \frac{3\AreaC(\Ball{R/h}{\vx/h} \cap
    \Body{\DSh}{h}, h)}{R^3}\,,\label{eq:dig-curvature-estimator-k}\\
    &\MeanCurvH{R}(\Body{\DSh}{h},\vx,h) \EqDef \frac{8}{3R}
    - \frac{4\VolC(\Ball{R/h}{\vx/h} \cap
    \Body{\DSh}{h}, h)}{\pi R^4}\,.\label{eq:dig-curvature-estimator-H}
  \end{align}
  %
  where $\AreaC(\Ball{R/h}{\vx/h} \cap \Body{\DSh}{h}, h) = h^2 \MCard(
  \Ball{R/h}{\vx/h} \cap \Body{\DSh}{h} )$ and $\VolC(\Ball{R/h}{\vx/h} \cap
  \Body{\DSh}{h}, h) = h^3 \MCard( \Ball{R/h}{\vx/h} \cap \Body{\DSh}{h} )$ are
  the number of digital points in the intersection between $\Body{\DSh}{h}$ and
  the ball $\Ball{R/h}{\vx/h}$ of radius $R/h$ centered on $\vx/h$, scaled by
  $h^d$.\todo[inline]{J: Hum... pas top...}
  %
  % Similarly, $\hat{\lambda}_1$
  % and $\hat{\lambda}_2$ are the two greatest eigenvalues of the covariance
  % matrix of the digital points in the intersection between $Z$ and the ball.
  %
\end{Definition}
%
We have proved that estimating the 2D curvature and 3D mean curvature on digital
objets with volumetric integral information have the multigrid convergence
property (setting $R = kh^\frac{1}{3}$ on convex shapes, where $k$ is a constant
related to the maximal curvature of the shape, with at least $C^3$-boundary and
bounded curvature) \cite{DGCI2013}. For short, when the digital objet becomes
finer and finer, \ie when the digitization step $h$ tends to zero, the estimated
quantity on $\Bd{\Body{\DSh}{h}}$  converges (theoretically and experimentally)
to the associated one on $\Bd{\Shape}$. More precisely, we have:
%
\begin{align}
\forall 0 < h \le h_0,\,\, &\forall \vx \in \Bd{\Shape},\,\,
\forall \vxH \in \Bd{\Body{\DSh}{h}} \text{~with~} \| \vxH -\vx\|_\infty \le h, \nonumber \\
&\CurvH{R}(\DSh, \vxH, h) = \Curv(\Shape, \vx) + O\left(h^{\frac{1}{3}}\right)\,,\\
&\MeanCurvH{R}(\DSh, \vxH, h) = \MeanCurv(\Shape, \vx) + O\left(h^{\frac{1}{3}}\right)\,.
\end{align}

In \cite{CVIU2014}, we have also defined the 3D digital principal curvature
estimators $\PrincCurvH{1}{R}$ and $\PrincCurvH{2}{R}$ on $Z\subset\Z^3$ based
on digital moments:
%
\begin{Definition}
  %
  Given the Gauss digitization $\Body{\DSh}{h}$ of a shape $\Shape \subset \R^3$
  scaled by the digitization step $h$, {\em 3D digital principal curvature
  estimators} are defined for any point $\vx \in \R^3$ as:
  %
  \begin{align}
    \PrincCurvH{1}{R}(\Body{\DSh}{h},\vx,h) &\EqDef \frac{6}{\pi {R}^6}(\hat{\lambda}_2 - 3\hat{\lambda}_1) + \frac{8}{5{{R}}} \,,\label{eq:dig-curvature-estimator-k1}\\
    \PrincCurvH{2}{R}(\Body{\DSh}{h},\vx,h) &\EqDef \frac{6}{\pi {R}^6}(\hat{\lambda}_1 - 3\hat{\lambda}_2) + \frac{8}{5{{R}}} \,,
    \label{eq:dig-curvature-estimator-k2}
  \end{align}
  %
  where $R_d = \frac{R}{h}$ is the digitized radius of the ball, and
  $\hat{\lambda}_1$ and $\hat{\lambda}_2$ are the two greatest eigenvalues of
  the covariance matrix of the digital points in the intersection between
  $\Body{\DSh}{h}$ and the ball $\Ball{R/h}{\vx/h}$ of radius $R/h$ centered on
  $\vx/h$.\todo[inline]{J: Pareil ici... pas top...}
  %
\end{Definition}
%
The covariance matrix needs to compute digital moments of order $0$, $1$ and $2$
(see Equation~20 of \cite{CVIU2014} for more details). We have also proved the
convergence of these estimators when setting the ball radius $h$ in $R =
kh^\frac{1}{3}$, where $k$ is a constant related to the maximal curvature of the
shape, on convex shapes with at least $C^3$-boundary and bounded curvature
\cite{CVIU2014}. More formally, we get:
%
\begin{align}
  \forall 0 < h \le h_0,\,\, &\forall \vx \in \Bd{\Shape},\,\,
  \forall \vxH \in \Bd{\Body{\DSh}{h}} \text{~with~} \| \vxH -\vx\|_\infty \le h, \nonumber \\
  &\PrincCurvH{1}{R}(\DigF{\Shape}{h},\vxH, h) = \PrincCurv{1}(\Shape,\vx) + O\left(h^{\frac{1}{3}}\right) \,,\\
  &\PrincCurvH{2}{R}(\DigF{\Shape}{h},\vxH, h) = \PrincCurv{2}(\Shape,\vx) + O\left(h^{\frac{1}{3}}\right) \,.
\end{align}

Additionally, eigenvectors associated with $\hat{\lambda}_1$ and
$\hat{\lambda}_2$ of the covariance matrix correspond to principal curvature
directions $\PrincDirH{1}{R}$ and $\PrincDirH{2}{R}$. The smallest eigvenvector
corresponds to the normal direction $\NormalDirH{R}$ at $\vx$. Convergence
results can be found in \cite{ChapterIICurvature}.\todo[inline]{Changer
ChapterIICurvature dans le bibtex...}

We have shown that the radius of the ball depends to the geometry of the
underlying shape. In \cite{DGCI2014}, we proposed a parameter-free estimation of
the radius of the ball by analyzing the shape \wrt the local geometry through to
the maximal digital straight segments of the boundary of the digital shape. In
\cite{SMI2015}, we analyze in scale-space (\ie with a range of radii) curvature
estimation of our algorithm for a given digital shape. This allows us to detect
features of the shape thanks to the behavior on singularities. In both methods, we need to explore the radius of the ball at different sizes and the computation time, depending to the size of the digital objet and the radius of the ball, is an obstacle.
\todo[inline]{Faut faire une transition...}
Computing curvatures from our algorithm in real-time can be really useful.

\section{Isosurface Extraction on GPU}
\label{sec:isos-extr-gpu}

In this section, we detail the adaptive isosurface extraction
algorithm. The proposed approach is based on an octree representation
of the input object on which an efficient adaptive triangulation
of the isosurface is constructed on GPU. Such approach is motivated by
the fact that the hierarchical representation of the object allows us
to handle large datasets and to locally adapt the level of details
with respect to the geometry or camera position. We first present the
octree representation and then the isosurface extraction from
hierarchical octree cells.

\subsection{Linear Octree Representation}

\begin{figure}[!htbp]
  \begin{center}
    \subfigure{}{\includegraphics[width=\textwidth]{figs/morton}}
    %%\subfigure{}{\includegraphics[height=0.17\textheight]{figs/partitioning}}
    %%\subfigure{}{\includegraphics[height=0.17\textheight]{figs/quadtree_activefront}}
  \end{center}
\caption{Morton codes associated to cells of a linear quatree. Each
   morton code of a child cell is obtained by adding a suffix to its
  parent code \emph{(left)}. The adaptive representation consists of
  quadtree cells whose depth is view point dependent
  \emph{(middle)}. Finally, adaptive Marching-Cubes is used to
  generate the triangulation \emph{(right)}.}
\label{fig_quadtree_partitionning}
\end{figure}

Representing a hierachical structure on GPU is usually challenging
since the GPU memory is limited and non consistent \todo{fix coherent/aligned/coalesced?}
memory access (\emph{e.g.} tree traversal using pointer dereferencing)
may lead to huge payload from cache misses.  Efficient spatial tree
encoding can be achieved using pointerless structures. We use
linear quadtrees or octrees to represent classical quadtree/octreee
trees, see for instance Gargantini
\cite{gargantini1982effective}. This structure consists in indexing
each cell by a \emph{Morton code}: the code of children cells are
defined by the code of the parent suffixed by two bits (in dimension
2, three bits in dimension 3) (see Figure
\ref{fig_quadtree_partitionning}-\emph{left}). A cell's code encodes
 its position with respect to its parent cell and its
complete path to the tree root. Hence, whatever their depth, all cell
codes are simply stored in a linear vector on memory. Furthermore,
cell operations such as subdivision, merging, neighbors access can be
efficiently implemented using bitwise operations on the Morton code.
In the following, we use the GPU implementation proposed by Dupuy
\textit{et al.}  \cite{dupuy2014quadtrees}. By using their approach, Morton
codes and bitwise operations are optimized to match with GPU hardware
requirements.

\subsection{Data parallel and adaptive mesh generation}



Using this spatial datastructure, triangulated mesh can be constructed
from a Marching-Cubes approach \cite{lorensen1987marching} (MC for short): the
triangulation is generated from local triangle patches computed on
local cell configurations. Since triangle patches are locally
computed, such approach is fully parallel and easy to implement on GPU
hardwares. However, since adjacent cells may not have the same depth
on the octree, original Lorensen and Cline's rules need to be
updated (see Figure~\ref{fig_quadtree_partitionning}-\emph{right}). Many authors have addressed this problem both for primal and
dual meshes
\cite{shu1995adaptive,schaefer2004dual,lengyel2010voxel,DBLP:journals/cgf/LewinerMPPL10,DBLP:journals/cvgip/LobelloDD14}.

In the following, we use the extension of MC configurations to handle
adaptive structures proposed by Lengyel \emph{et al.}
\cite{lengyel2010voxel}. First this approach constrains the octree
structure in order to make sure that the depth difference between any
two adjacent cells is at most one. Then, Lengyel \emph{et al.} propose
specific MC configurations for such transition cells,  leading to a
crack-free triangulation.

Similarly to original MC algorithm, this approach is perfectly adapted
to GPU hardwares: Given a set of cells (a vector of morton codes),
each triangle patch can be constructed in parallel (done by
in the \emph{geometry shader} in the GPU graphic pipeline).

\subsection{Level of Details Criteria and Temporal Updates}


As illustrated in Figure
\ref{fig_quadtree_partitionning}-\emph{middle}, we propose a viewpoint
dependent criterion to decide if a cell needs to be refined: the
closer we are to the camera, the finer the cells are. In addition to
the distance criterion, we define an angular criterion to refine cells
within the camera frustrum. When rendering a mesh, a key stage is the
rasterization which digitizes triangles projected onto the
screen. As a consequence, having several triangles whose projections
lie inside the same pixel is something we should prevent. Hence,
distance criterion can be set in order to both control the geometrical
approximation and to ensure that cells project onto more than one
pixel. This does not prevent all triangles within such cells to be
projected into more than one pixel but gives us a fast criterion to
decide if a cell should be split or not.  Figure \ref{fig_lod_octree}
illustrates the level of details (LoD for short) criterion we
use. More precisely, in dimension 2, if $\alpha$ denotes the viewing
angle, an object at distance $d$ from the camera with diameter greater than
 $2\cdot d\cdot\tan(\alpha)$
 is projected into more than one pixel
(see Figure~\ref{fig_lod_octree}-\emph{left}). Hence, the distance
criterion is based on the ratio (\emph{visibility ratio} in the
following)between the cell diameter $l(c)$ (power of 2 depending on
the depth), and
$2\cdot d_c\cdot\tan(\alpha)$, $d_c$ being the distance between the cell center and the camera. For a given cell $c$,
split and merge decision are based on this visibility ratio:
\begin{itemize}
\item $c$ is split if its children cells have a visibility ratio
  greater than  constant $k$\,;
\item $c$ and its sibling cells are merged if their parent cell $c'$
  have av visibility ratio lower than $k$\;
\item otherwise, the cell $c$ stays for the next frame.
\end{itemize}
%
\begin{figure}[!h]
  \begin{center}
    \begin{overpic}[width=4cm]{figs/criterion}
      \put(33,40){$\alpha$}
      \put(50,45){$d_c$}
      \put(95,65){$l(c)$}
    \end{overpic}~~~~~
    \includegraphics[width=4cm]{viewlod2_small}~~~~~
    \includegraphics[width=3.5cm]{subdivision}
  \end{center}
  \caption{Notations \emph{(left)} and adaptive meshing in dimension 2 using the LoD distance and
    angular criterion \emph{(middle)}. Based on LoD criterion
    evaluation, the cell buffer is
  updated between each frame \emph{(right)}.}
  \label{fig_lod_octree}
\end{figure}
%
In addition to the distance criterion, we add an angular term in order
to prevent subdivision of cells far from the camera frustrum (see
Figure~\ref{fig_lod_octree}-\emph{middle}). We do not go into the
details but please note that stay, split and merge decisions of all cells are computed in
parallel from all cell morton codes.

Once decisions have been made, a new set of cells are sent to the mesh
generation step described above. Updating the cell buffer can be
efficiently implemented on GPU hardware as illustrated in
Figure~\ref{fig_lod_octree}-\emph{right}.

Finally, before constructing the triangulation from remaining cells
and transition cells, geometrical culling is performed in order to
skip the triangle patch construction which are not visible. Figure
\ref{fig_pipeline} illustrates the overall fully data parallel
pipeline.

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.9\textwidth]{figs/pipeline}
  \caption{ Summary our GPU pipeline. Data buffers are
    represented in green and computations in red. Each computation
    retrieves data from a buffer and fills a new one. }
  \label{fig_pipeline}
\end{figure}




\section{Interactive Computation on GPU}
\label{sec:inter-visu-gpu}

\begin{figure}
  \begin{center}
    \includegraphics[width=\textwidth]{figs/approx}
  \end{center}
  \caption{BALBLABLABLA.}
  \label{fig:approx}
\end{figure}




\section{Experiments}
\label{sec:experiments}



\section{Conclusion and Discussion}
\label{sec:discussion}



\appendix
\section{Hierarchical Probing Algorithm}



A {\em cell} is a tuple $(k,x,y,z)$, which represents a region of the space of size $2^k \times
2^k \times 2^k$, characterized by its integer coordinates $x,y,z$,
with $0 \le x < 2^k$, $0 \le y < 2^k$, $0 \le z < 2^k$. Cells forms an
octree decomposition of a cubic space. We use functions Up, Down and
Next to navigate between cells.


\begin{algorithm}
\KwIn{Integers $p,q,r$ \tcp*{the moment orders, with $0 \le p+q+r \le 2$}}
\KwIn{Integer $k$ \tcp*{$(2^k)^3$ is the size of the digital shape image}}
\KwIn{Mipmap $V$ \tcp*{array of $k+1$ images of sizes $(2^k)^3,  (2^{k-1})^3, \ldots,  1^3$}}
\KwIn{Integers $x_0,y_0,z_0$, Real $r$ \tcp*{Ball radius $r$ and center $(x_0,y_0,z_0)$}}
\KwOut{Real $m$ \tcp*{estimation of the $p,q,r$-moment of $X \cap B_r(x_0,y_0,z_0)$}}
\KwData{Cell $c :=  (k,0,0,0)$ \tcp*{Starts from biggest cell}}
\KwData{Integer $n := 2^k$ \tcp*{Size of each cell}}
\KwData{Real $d,\delta,l$ \tcp*{variables for intermediate computations}}
\Begin{
    m := 0 \;
    \Repeat{$c[0] = k$}{
      \tcp{Distance between cell and ball centers}
      $d := \frac{1}{2}\| 2^k(2c[1]+1,2c[2]+1,2c[3]+1) - (2x_0+1,2y_0+1,2z_0+1) \|_2$\;
      $\delta := \frac{\sqrt{3}}{2}2^{c[0]}$ \tcp*{half-length of cell diagonal}
      \If(\tcp*[f]{Is it a unit cell ?}){$c[0] = 0$}{
        \If(\tcp*[f]{Is cell center inside ball ?}){$d^2 \le r^2$}{
          $m := m + V[c] * (2^k c[1])^p * (2^k c[2])^q * (2^k c[3])^r$ \;
        }
        $c := \textsc{Next}(c)$ \tcp*{Go to next cell}
      } \Else{
        $l := \max(r-\delta,0)$\;
        \If(\tcp*[f]{Is cell completely inside ball ?}){$d^2 < l^2$}{
          $m := m + V[c] * (2^k c[1])^p * (2^k c[2])^q * (2^k c[3])^r$\;
          $c := \textsc{Next}(c)$ \tcp*{Go to next cell}
        }\ElseIf(\tcp*[f]{Is cell outside ball ?}){$d^2 > (r+\delta)^2$}{
          $c := \textsc{Next}(c)$ \tcp*{Go to next cell}
        }\lElse(\tcp*[f]{Go to a finer cell}){$c := \textsc{Down}(c)$}
      }
    }
    \Return{m}\;
  }
  \caption{Derecursified hierarchical algorithm for computing the
    $p,q,r$-moment of set $X \cap B_r(x_0,y_0,z_0)$, given a mipmap
    $V$ that represents the volume of a shape $X$ in each cell, and
    ball parameters $x_0,y_0,z_0,r$.}
\end{algorithm}

\begin{function}
  \caption{Up( Cell $c$ ) : Cell}
  \Return{Cell( $c[0]+1$, $c[1]/2$, $c[2]/2$, $c[3]/2$ )}
\end{function}
\begin{function}
  \caption{Down( Cell $c$ ) : Cell}
  \Return{Cell( $c[0]-1$, $c[1]*2$, $c[2]*2$, $c[3]*2$ )}
\end{function}
\begin{function}
  \caption{Next( Cell $c$ ) : Cell}
  \lWhile{$\mathrm{Odd}(c[1])$ and $\mathrm{Odd}(c[2])$ and $\mathrm{Odd}(c[3])$}{$c := \mathrm{Up}(c)$}
  \lIf{$\mathrm{Even}(c[1])$}{$c[1] := c[1]+1$}
  \Else{$c[1] := c[1] - 1$\;
    \lIf{$\mathrm{Even}(c[2])$}{$c[2] := c[2]+1$}
    \Else{$c[2] := c[2] - 1$\;
      $c[3] := c[3]+1$}
  }
  \Return{c}
\end{function}



\bibliographystyle{splncs03}
\bibliography{ictv}
\end{document}
