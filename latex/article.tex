\documentclass{llncs}
\usepackage{enumerate}% http://ctan.org/pkg/enumerate
\usepackage{multirow}
\usepackage{amsmath,amssymb}
\usepackage{url}
\usepackage{overpic}
\usepackage{enumerate}
\usepackage{graphicx}        % standard LaTeX graphics tool
\usepackage{tikz}        % standard LaTeX graphics tool
%\usetikzlibrary{arrows}
%\usetikzlibrary{quotes,angles}
\usepackage{subfigure}                                 % authors: subfigures
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}   % authors: last version of algorithm display
\usepackage{todonotes}



\newcommand{\ie}{\emph{i.e.} }
\newcommand{\eg}{\emph{e.g.} }
\newcommand{\wnlog}{w.l.o.g. }
\newcommand{\Zr}{\ensuremath{\mathbb{Z}[\rho]}}
\newcommand{\C}{\ensuremath{\mathbb{C}}}
\newcommand{\E}{\ensuremath{\mathcal{E}}}

\title{Interactive Curvature Tensor Visualization on Digital
Surfaces\thanks{This work has been mainly funded by XXXXXXX research grants.}}

\author{H\'el\`ene Perrier\inst{1}\and J\'eré\'emy Levallois\inst{1,2}\and David
Coeurjolly\inst{1}\and Jean-Philippe Farrugia\inst{1}\and Jean-Claude
Iehl\inst{1}\and Jacques-Olivier Lachaud\inst{2} }

%\address[liris]{Universit\'e de Lyon, CNRS, INSA-Lyon, LIRIS, UMR5205, F-69621, France}
%\address[lama]{Universit\'e de Savoie, CNRS, LAMA, UMR 5127, F-73776, France}

 \institute{ Universit\'e de Lyon, CNRS\\
   LIRIS, UMR5205, F-69621, France
%   \email{\{david.coeurjolly,jeremy.levallois\}@liris.cnrs.fr}
   \and
Universit\'e de Savoie, CNRS\\
LAMA, UMR5127, F-73776, France\\
%\email{jacques-olivier.lachaud@univ-savoie.fr}
}

\graphicspath{{./figs/}}
\input{macros}
\begin{document}
\maketitle


\begin{abstract}\sloppy
  Interactive visualization is a very convenient tool to explore
  complex scientific data or to explore different parameter settings
  for a given processing algorithm. In this article, we present a tool
  to efficiently explore the curvature tensor on the boundary of
  potentially large and dynamic digital objects (mean and gaussian curvature,
  principal curvatures, principal directions and normal vector
  field). More precisely, we combine a fully parallel pipeline on GPU
  to extract an adaptive triangulated isosurface of the digital
  object, with a curvature tensor estimation at each surface point
  based on integral invariants. Integral invariants being parametrized
  by a given ball radius, our proposal allows us to explore
  interactively different radii and thus select the appropriate scale
  to which the computation is performed and visualized.


\keywords{Isosurface Visualization, Digital Geometry, Curvature
  Estimation, GPU.}
\end{abstract}

\section{Introduction}
\label{sec:introduction}



\textbf{Contributions}




\section{Curvature Tensor Estimation}
\label{sec:curv-tens-estim}

In our context, we consider digital shapes (any subset of $\Z^d$) and
boundaries of digital shapes. We denote by $\DSh$ the Gauss
digitization of $\Shape$ in a $d-$dimensional grid with grid step $h$,
\emph{i.e.}  $\DSh = \Shape \cap (h\Z)^d$. For such digitized set
$\DigShape$, $\Body{\DigShape}{h}$ \todo{DC: $\partial\Body{.}{h}$,
  pas $\Body{.}{h}$, c'est pas un bord fait de i-cell} denotes its
topological boundary, seen as a cellular Cartesian complex (See
Fig. \ref{fig:notations}-b). It is thus composed of $0$-cells and
$1$-cells (resp. \emph{pointels} and \emph{linels}), and, for $d=3$,
with $2$-cells ({\em surfels}), embedded in the digital grid.

\begin{figure}[t]{\small
    \begin{center}
      \subfigure[]{\begin{overpic}[width=5cm]{figs/integral2D_2}
          \put(42,28){$\times$}
          \put(46,31){$\vx$}
          \put(55,45){$B_R(\vx)$}
          \put(1,10){$\dS$}
          \put(20,10){$\Shape$}
      \end{overpic}}
      \subfigure[]{\begin{overpic}[width=5cm]{figs/notation_2}
          \put(44.5,25){$\vp$}
          \put(42,28.5){$\times$}
          \put(45,32.5){$\vx$}
          \put(45,16.5){$h$}
          %\put(88,39){$\Proj(p)$}
          \put(3,11){$\partial \Shape$}
          \put(15,7){$\Body{\DigShape}{h}$}
      \end{overpic}}
      \vspace{-0.4cm}
    \end{center}}
    \caption{Integral invariant computation $(a)$ and
      notations $(b)$ in dimension 2 \cite{CVIU2014}.\label{fig:notations}}
\end{figure}

% We define the volumetric integral as follow:
% \begin{Definition}
%   %
%   Given $\Shape \in \Shapes$ and a radius $R \in \R^{+*}$, the volumetric
%   integral $V_R(\vx)$ at $\vx \in \dS$ is given by:
%   %
%   \begin{equation}
%     V_R(\vx) \EqDef \int_{B_R(\vx)} \chi(\vp) d\vp \,,
%   \end{equation}
%   %
%   where $B_R(\vx)$ is the Euclidean ball of radius $R$ centered on $\vx$, and $\chi(\cdot)$ the characteristic function of $\Shape$. In dimension 2, we denote $A_R(\vx)$ such quantity.
%   %
% \end{Definition}

In \cite{DGCI2013}, we have defined the 2D digital curvature estimator
$\CurvH{R}$ and the 3D digital mean curvature estimator $\MeanCurvH{R}$ based on
the digital volumetric integral $V_{R_d}$ (or $A_{R_d}$ in dimension 2) of the
intersection between the shape $\Shape$ and a ball of digital radius $R_d$:

\begin{Definition}
  %
  Given $\DigShape \subset \Z^2$ (or $\Z^3$ for 3D mean curvature estimator) and
  $h$ a gridstep, {\em digital curvature estimators} are defined for any pointel
  $\vp \in \Body{\DigShape}{h}$ as:
  %
  \begin{align}
   \CurvH{R}(\DigShape,\vp) &\EqDef \frac{1}{h} \left( \frac{3 \pi}{2 R_d} - \frac{3 A_{R_d}(\vp)}{{R_d}^3} \right),\label{eq:dig-curvature-estimator-k}\\
   \MeanCurvH{R}(\DigShape,\vp) &\EqDef \frac{1}{h} \left( \frac{8}{3 R_d} - \frac{4V_{R_d}(\vp)}{{\pi R_d}^4} \right),\label{eq:dig-curvature-estimator-H}
  %  \\
  %  \hat{\kappa}^{1}(\DigShape,p) &\EqDef \frac{1}{h} \left( \frac{6(\hat{\lambda}_2 - 3\hat{\lambda}_1)}{\pi {{R_d}}^6} + \frac{8}{5{{R_d}}} \right),\label{eq:dig-curvature-estimator-k1}\\
  %  \hat{\kappa}^{2}(\DigShape,p) &\EqDef \frac{1}{h} \left( \frac{6(\hat{\lambda}_1 - 3\hat{\lambda}_2)}{\pi {{R_d}}^6} + \frac{8}{5{{R_d}}} \right),
  %  \label{eq:dig-curvature-estimator-k2}
  \end{align}
  %
  where $R_d = \frac{R}{h}$ is the digitized radius of the ball, and
  $A_{R_d}(p)$ and $V_{R_d}(p)$ are the number of digital points in the
  intersection between $\DigShape$ and the ball.
  % Similarly, $\hat{\lambda}_1$
  % and $\hat{\lambda}_2$ are the two greatest eigenvalues of the covariance
  % matrix of the digital points in the intersection between $Z$ and the ball.
  %
\end{Definition}

We have proved that estimating the 2D curvature and 3D mean curvature on digital
objets with volumetric integral information have the multigrid convergence
property (setting $R = kh^\frac{1}{3}$ on convex shapes with at least
$C^3$-boundary and bounded curvature) \cite{CVIU2014}. For short, when the digital objet becomes
finer and finer, \ie when the digitization step $h$ tends to zero, the estimated
quantity on $\DSh$  converges (theoretically and experimentally) to
the associated one on $\partial\Shape$. More precisely, we have:

\begin{align}
  \CurvH{R}(\DSh,\vx,h) &= \Curv(\Shape,\vx) + O(h^{\frac{1}{3}}),\\
  \MeanCurvH{R}(\DSh,\vx,h) &= \MeanCurv(\Shape,\vx) + O(h^{\frac{1}{3}}) \,.
\end{align}

In \cite{CVIU2014}, we have also defined the 3D digital principal curvature estimators $\kappa^1_{R}$ and $\kappa^2_{R}$
on $Z\subset\Z^3$:
\begin{Definition}
  %
  Given $\DigShape \subset \Z^3$ and
  $h$ a gridstep, {\em 3D digital principal curvature estimators} are defined for any pointel
  $\vp \in \Body{\DigShape}{h}$ as:
  %
  \begin{align}
    \hat{\kappa}^{1}(\DigShape,p) &\EqDef \frac{1}{h} \left( \frac{6(\hat{\lambda}_2 - 3\hat{\lambda}_1)}{\pi {{R_d}}^6} + \frac{8}{5{{R_d}}} \right),\label{eq:dig-curvature-estimator-k1}\\
    \hat{\kappa}^{2}(\DigShape,p) &\EqDef \frac{1}{h} \left( \frac{6(\hat{\lambda}_1 - 3\hat{\lambda}_2)}{\pi {{R_d}}^6} + \frac{8}{5{{R_d}}} \right),
    \label{eq:dig-curvature-estimator-k2}
  \end{align}
  %
  where $R_d = \frac{R}{h}$ is the digitized radius of the ball, and
  $\hat{\lambda}_1$ and $\hat{\lambda}_2$ are the two greatest eigenvalues of the covariance matrix of the digital points in the intersection between $Z$ and the ball.
  %
\end{Definition}

% When dealing with digital data in a multigrid framework, we must pay
% attention to on how quantities expend where decreasing the grid step
% $h$. For example, if you fixed $R$, the digital radius will be $R_d
% = \frac{5}{h}$ and increase when $h$ tends to zero.
Authors of \cite{CVIU2014} have proved the convergence of these
estimators when setting the ball radius $h$ in $R = kh^\frac{1}{3}$,
where $k$ is a constant related to the maximal curvature of the
shape. More formally, we get:
\begin{align}
  \hat{\kappa}^1_{R}(\DigF{\Shape}{h},p) &= \kappa^1(X,x) + O(h^{\frac{1}{3}}),\\
  \hat{\kappa}^2_{R}(\DigF{\Shape}{h},p) &= \kappa^2(X,x) + O(h^{\frac{1}{3}}),
\end{align}
when the ball radius is $R = kh^\frac{1}{3}$.
Additionally, eigenvectors associated with $\hat{\lambda}_1$ and
$\hat{\lambda}_2$ correspond to principal curvature directions. The
smallest eigvenvector corresponds to the normal direction at $p$.
\todo[inline]{finir en citant le chapitre (ou CVIU) pour convergence directions}

\todo[inline]{petite phrase pour dire que R depend de la géométrie
  (citer DGCI pour paramter free, ou SMI pour dire qu'on peut s'en
  servir pour feature) et qu'il faut explorer R}

\section{Isosurface Extraction on GPU}
\label{sec:isos-extr-gpu}

In this section, we detail the adaptive isosurface extraction
algorithm. The proposed approach is based on an octree representation
of the input object on which an efficient adaptive triangulation
of the isosurface is constructed on GPU. Such approach is motivated by
the fact that the hierarchical representation of the object allows us
to handle large datasets and to locally adapt the level of details
with respect to the geometry or camera position. We first present the
octree representation and then the isosurface extraction from
hierarchical octree cells.

\subsection{Linear Octree Representation}

\begin{figure}[!htbp]
  \begin{center}
    \subfigure{}{\includegraphics[width=\textwidth]{figs/morton}}
    %%\subfigure{}{\includegraphics[height=0.17\textheight]{figs/partitioning}}
    %%\subfigure{}{\includegraphics[height=0.17\textheight]{figs/quadtree_activefront}}
  \end{center}
\caption{Morton codes associated to cells of a linear quatree. Each
   morton code of a child cell is obtained by adding a suffix to its
  parent code \emph{(left)}. The adaptive representation consists of
  quadtree cells whose depth is view point dependent
  \emph{(middle)}. Finally, adaptive Marching-Cubes is used to
  generate the triangulation \emph{(right)}.}
\label{fig_quadtree_partitionning}
\end{figure}

Representing a hierachical structure on GPU is usually challenging
since the GPU memory is limited and non consistent \todo{fix coherent/aligned/coalesced?}
memory access (\emph{e.g.} tree traversal using pointer dereferencing)
may lead to huge payload from cache misses.  Efficient spatial tree
encoding can be achieved using pointerless structures. We use
linear quadtrees or octrees to represent classical quadtree/octreee
trees, see for instance Gargantini
\cite{gargantini1982effective}. This structure consists in indexing
each cell by a \emph{Morton code}: the code of children cells are
defined by the code of the parent suffixed by two bits (in dimension
2, three bits in dimension 3) (see Figure
\ref{fig_quadtree_partitionning}-\emph{left}). A cell's code encodes
 its position with respect to its parent cell and its
complete path to the tree root. Hence, whatever their depth, all cell
codes are simply stored in a linear vector on memory. Furthermore,
cell operations such as subdivision, merging, neighbors access can be
efficiently implemented using bitwise operations on the Morton code.
In the following, we use the GPU implementation proposed by Dupuy
\textit{et al.}  \cite{dupuy2014quadtrees}. By using their approach, Morton
codes and bitwise operations are optimized to match with GPU hardware
requirements.

\subsection{Data parallel and adaptive mesh generation}



Using this spatial datastructure, triangulated mesh can be constructed
from a Marching-Cubes approach \cite{lorensen1987marching} (MC for short): the
triangulation is generated from local triangle patches computed on
local cell configurations. Since triangle patches are locally
computed, such approach is fully parallel and easy to implement on GPU
hardwares. However, since adjacent cells may not have the same depth
on the octree, original Lorensen and Cline's rules need to be
updated (see Figure~\ref{fig_quadtree_partitionning}-\emph{right}). Many authors have addressed this problem both for primal and
dual meshes
\cite{shu1995adaptive,schaefer2004dual,lengyel2010voxel,DBLP:journals/cgf/LewinerMPPL10,DBLP:journals/cvgip/LobelloDD14}.

In the following, we use the extension of MC configurations to handle
adaptive structures proposed by Lengyel \emph{et al.}
\cite{lengyel2010voxel}. First this approach constrains the octree
structure in order to make sure that the depth difference between any
two adjacent cells is at most one. Then, Lengyel \emph{et al.} propose
specific MC configurations for such transition cells,  leading to a
crack-free triangulation.

Similarly to original MC algorithm, this approach is perfectly adapted
to GPU hardwares: Given a set of cells (a vector of morton codes),
each triangle patch can be constructed in parallel (done by
in the \emph{geometry shader} in the GPU graphic pipeline).

\subsection{Level of Details Criteria and Temporal Updates}


As illustrated in Figure
\ref{fig_quadtree_partitionning}-\emph{middle}, we propose a viewpoint
dependent criterion to decide if a cell needs to be refined: the
closer we are to the camera, the finer the cells are. In addition to
the distance criterion, we define an angular criterion to refine cells
within the camera frustrum. When rendering a mesh, a key stage is the
rasterization which digitizes triangles projected onto the
screen. As a consequence, having several triangles whose projections
lie inside the same pixel is something we should prevent. Hence,
distance criterion can be set in order to both control the geometrical
approximation and to ensure that cells project onto more than one
pixel. This does not prevent all triangles within such cells to be
projected into more than one pixel but gives us a fast criterion to
decide if a cell should be split or not.  Figure \ref{fig_lod_octree}
illustrates the level of details (LoD for short criterion) we
use. More precisely, in dimension 2, if $\alpha$ denotes the viewing
angle, an object at distance $d$ from the camera with diameter greater than
\todo{Extract formulas from text with dots list}\todo{DC: I don't
  understand what you mean} $2\cdot d\cdot\tan(\alpha)$
 is projected into more than one pixel
(see Figure~\ref{fig_lod_octree}-\emph{left}). Hence, the distance
criterion is based on the ratio (\emph{visibility ratio} in the
following)between the cell diameter $l(c)$ (power of 2 depending on
the depth), and
$2\cdot d_c\cdot\tan(\alpha)$ \todo{idem}
,$d_c$ being the distance between the cell center and the camera. For a given cell $c$,
split and merge decision are based on this visibility ratio:
\begin{itemize}
\item $c$ is split if its children cells have a visibility ratio
  greater than  constant $k$\,;
\item $c$ and its sibling cells are merged if their parent cell $c'$
  have av visibility ratio lower than $k$\;
\item otherwise, the cell $c$ stays for the next frame.
\end{itemize}
%
\begin{figure}[!h]
  \begin{center}
    \begin{overpic}[width=4cm]{figs/criterion}
      \put(33,40){$\alpha$}
      \put(50,45){$d_c$}
      \put(95,65){$l(c)$}
    \end{overpic}~~~~~
    \includegraphics[width=4cm]{viewlod2_small}~~~~~
    \includegraphics[width=3.5cm]{subdivision}
  \end{center}
  \caption{Notations \emph{(left)} and adaptive meshing in dimension 2 using the LoD distance and
    angular criterion \emph{(middle)}. Based on LoD criterion
    evaluation, the cell buffer is
  updated between each frame \emph{(right)}.}
  \label{fig_lod_octree}
\end{figure}
%
In addition to the distance criterion, we add an angular term in order
to prevent subdivision of cells far from the camera frustrum (see
Figure~\ref{fig_lod_octree}-\emph{middle}). We do not go into the
details but please note that stay, split and merge decisions of all cells are computed in
parallel from all cell morton codes.

Once decisions have been made, a new set of cells are sent to the mesh
generation step described above. Updating the cell buffer can be
efficiently implemented on GPU hardware as illustrated in
Figure~\ref{fig_lod_octree}-\emph{right}.

Finally, before constructing the triangulation from remaining cells
and transition cells, geometrical culling is performed in order to
skip the triangle patch construction which are not visible. Figure
\ref{fig_pipeline} illustrates the overall fully data parallel
pipeline.

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.9\textwidth]{figs/pipeline}
  \caption{ Summary our GPU pipeline. Data buffers are
    represented in green and computations in red. Each computation
    retrieves data from a buffer and fills a new one. }
  \label{fig_pipeline}
\end{figure}




\section{Interactive Computation on GPU}
\label{sec:inter-visu-gpu}






\section{Experiments}
\label{sec:experiments}



\section{Conclusion and Discussion}
\label{sec:discussion}



\appendix
\section{Hierarchical Probing Algorithm}



A {\em cell} is a tuple $(k,x,y,z)$, which represents a region of the space of size $2^k \times
2^k \times 2^k$, characterized by its integer coordinates $x,y,z$,
with $0 \le x < 2^k$, $0 \le y < 2^k$, $0 \le z < 2^k$. Cells forms an
octree decomposition of a cubic space. We use functions Up, Down and
Next to navigate between cells.


\begin{algorithm}
\KwIn{Integers $p,q,r$ \tcp*{the moment orders, with $0 \le p+q+r \le 2$}}
\KwIn{Integer $k$ \tcp*{$(2^k)^3$ is the size of the digital shape image}}
\KwIn{Mipmap $V$ \tcp*{array of $k+1$ images of sizes $(2^k)^3,  (2^{k-1})^3, \ldots,  1^3$}}
\KwIn{Integers $x_0,y_0,z_0$, Real $r$ \tcp*{Ball radius $r$ and center $(x_0,y_0,z_0)$}}
\KwOut{Real $m$ \tcp*{estimation of the $p,q,r$-moment of $X \cap B_r(x_0,y_0,z_0)$}}
\KwData{Cell $c :=  (k,0,0,0)$ \tcp*{Starts from biggest cell}}
\KwData{Integer $n := 2^k$ \tcp*{Size of each cell}}
\KwData{Real $d,\delta,l$ \tcp*{variables for intermediate computations}}
\Begin{
    m := 0 \;
    \Repeat{$c[0] = k$}{
      \tcp{Distance between cell and ball centers}
      $d := \frac{1}{2}\| 2^k(2c[1]+1,2c[2]+1,2c[3]+1) - (2x_0+1,2y_0+1,2z_0+1) \|_2$\;
      $\delta := \frac{\sqrt{3}}{2}2^{c[0]}$ \tcp*{half-length of cell diagonal}
      \If(\tcp*[f]{Is it a unit cell ?}){$c[0] = 0$}{
        \If(\tcp*[f]{Is cell center inside ball ?}){$d^2 \le r^2$}{
          $m := m + V[c] * (2^k c[1])^p * (2^k c[2])^q * (2^k c[3])^r$ \;
        }
        $c := \textsc{Next}(c)$ \tcp*{Go to next cell}
      } \Else{
        $l := \max(r-\delta,0)$\;
        \If(\tcp*[f]{Is cell completely inside ball ?}){$d^2 < l^2$}{
          $m := m + V[c] * (2^k c[1])^p * (2^k c[2])^q * (2^k c[3])^r$\;
          $c := \textsc{Next}(c)$ \tcp*{Go to next cell}
        }\ElseIf(\tcp*[f]{Is cell outside ball ?}){$d^2 > (r+\delta)^2$}{
          $c := \textsc{Next}(c)$ \tcp*{Go to next cell}
        }\lElse(\tcp*[f]{Go to a finer cell}){$c := \textsc{Down}(c)$}
      }
    }
    \Return{m}\;
  }
  \caption{Derecursified hierarchical algorithm for computing the
    $p,q,r$-moment of set $X \cap B_r(x_0,y_0,z_0)$, given a mipmap
    $V$ that represents the volume of a shape $X$ in each cell, and
    ball parameters $x_0,y_0,z_0,r$.}
\end{algorithm}

\begin{function}
  \caption{Up( Cell $c$ ) : Cell}
  \Return{Cell( $c[0]+1$, $c[1]/2$, $c[2]/2$, $c[3]/2$ )}
\end{function}
\begin{function}
  \caption{Down( Cell $c$ ) : Cell}
  \Return{Cell( $c[0]-1$, $c[1]*2$, $c[2]*2$, $c[3]*2$ )}
\end{function}
\begin{function}
  \caption{Next( Cell $c$ ) : Cell}
  \lWhile{$\mathrm{Odd}(c[1])$ and $\mathrm{Odd}(c[2])$ and $\mathrm{Odd}(c[3])$}{$c := \mathrm{Up}(c)$}
  \lIf{$\mathrm{Even}(c[1])$}{$c[1] := c[1]+1$}
  \Else{$c[1] := c[1] - 1$\;
    \lIf{$\mathrm{Even}(c[2])$}{$c[2] := c[2]+1$}
    \Else{$c[2] := c[2] - 1$\;
      $c[3] := c[3]+1$}
  }
  \Return{c}
\end{function}



\bibliographystyle{splncs03}
\bibliography{ictv}
\end{document}
